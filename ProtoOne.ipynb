{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current Problem\n",
    "\n",
    "#task split function creates a chain of tasks, but it should be a hierarchy\n",
    "\n",
    "#provide taskSolver most helpful results of task childs (sometimes context is polutet)\n",
    "\n",
    "#results are added in the wrong order in dummySolver\n",
    "\n",
    "#an return all usefull information in this text for this task( and the context of the taskpath)\n",
    "\n",
    "# minor:Check if task is solved correctly could be done with fewer tokens\n",
    "\n",
    "# https://www.reddit.com/r/AutoGPT/comments/12k4al2/found_the_winning_sauce/\n",
    "\n",
    "#IDEA Make the VirtualFileOperations so they contain a message what has been done. This could be used to create a log of the process that can be used to create the TaskResultMessage\n",
    "\n",
    "# use caching of LLM calls\n",
    "\n",
    "#make tooluse an process:\n",
    "    # what you wane do? i suggest tools?\n",
    "    # what suggested tool you wane use?\n",
    "    # heres a description how exacly to use that tool\n",
    "    # execute the tool\n",
    "\n",
    "#fundamental a workingdir with write and read access and a obligatory paginated output is needed\n",
    "#solver could have verry simple read commands like \n",
    "#READ FILENAME PAGE\n",
    "#WRITE FILENAME PAGE\n",
    "#LIST FILENAMES\n",
    "\n",
    "#TODO READ FIle with sourounding should indicate where surounding is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we gone need many types of BrainFunctions\n",
    "\n",
    "#Tasks\n",
    "    #tasks have subtasks\n",
    "    #if a task couldn't be solved, it can be retried later\n",
    "    #tasks should consist of descriptions results and parameters\n",
    "\n",
    "#taskpath \n",
    "    #Path from Objectiv Task to current Task. Creates a great context for the current task.\n",
    "\n",
    "#Atomic Tasks are tasks with no subtasks\n",
    "\n",
    "#Central control\n",
    "#    decides what to do next.\n",
    "#       Split Tast\n",
    "#       Solve Task\n",
    "#       Retry Task\n",
    "#       Improve Task Solution\n",
    "\n",
    "#TaskSplitter Task->List[Task] (simpler tasks)\n",
    "#TaskSolver Task->Result + Optional List[Task] (new tasks encountered during solving, debugging, etc.)\n",
    "#Task Duplicate Detector List[Task]->List[Task]\n",
    "#Task Merger List[Task]->Task\n",
    "#Task Selector \n",
    "#Function tath gathers all the results that can be helpfull to solve a task\n",
    "#asign solved task to other tasks that could benefit from the results\n",
    "#ask for most complex task and split it into subtasks\n",
    "\n",
    "\n",
    "#JSON Stuffer Takes result of Brainfunction and stuffs it into a JSON string\n",
    "#retries with \"doesnt look like correct JSNO jet\" until its successfull parsed into object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:The File FinalAGI.py is loaded for you. Simply call the ReadFile Command to read each Page of that file. After you have read a page, apend a summary to the file summary.txt. After you have read all pages, call the FINISH command and write a short summary of your findings.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 673\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[39m# agent=Agent(\"Look at Page 5 of the file FinalAGI.py. Can you find a way to improve the code on that page? If so, replace the code on that page with your improved code. After you have replaced the code, create a file called changes.txt and write a short summary of your changes.\")\u001b[39;00m\n\u001b[0;32m    672\u001b[0m agent\u001b[39m.\u001b[39mVirtualFileSystem\u001b[39m.\u001b[39mload_from_disk(\u001b[39m\"\u001b[39m\u001b[39mFinalAGI.py\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 673\u001b[0m agent\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m    674\u001b[0m agent\u001b[39m.\u001b[39mVirtualFileSystem\u001b[39m.\u001b[39mdump_all()\n\u001b[0;32m    676\u001b[0m \u001b[39mprint\u001b[39m(agent\u001b[39m.\u001b[39mObjectiv\u001b[39m.\u001b[39mResultDescription)\n",
      "Cell \u001b[1;32mIn[4], line 663\u001b[0m, in \u001b[0;36mAgent.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    661\u001b[0m currentTask\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTaskpool\u001b[39m.\u001b[39mget_task_ready_to_solve()\n\u001b[0;32m    662\u001b[0m \u001b[39m#self.DummySolveAtomicTask(currentTask)\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSolveAtomicTask(currentTask)\n\u001b[0;32m    664\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mObjectiv\u001b[39m.\u001b[39mdisplay()\n",
      "Cell \u001b[1;32mIn[4], line 595\u001b[0m, in \u001b[0;36mAgent.SolveAtomicTask\u001b[1;34m(self, task, max_retries, verbose)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mwhile\u001b[39;00m toLong:\n\u001b[0;32m    594\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m         workingLog\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat(ContextHeader \u001b[39m+\u001b[39;49m workingLog))\n\u001b[0;32m    596\u001b[0m         toLong \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[39mexcept\u001b[39;00m InvalidRequestError:\n",
      "Cell \u001b[1;32mIn[4], line 321\u001b[0m, in \u001b[0;36mCachedChat.__call__\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, messages, stop\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39mreturn\u001b[39;00m AIMessage(\n\u001b[1;32m--> 321\u001b[0m         content\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_chat(messages, stop)\n\u001b[0;32m    322\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[4], line 353\u001b[0m, in \u001b[0;36mCachedChat.run_chat\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[39mif\u001b[39;00m cached_response:\n\u001b[0;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m cached_response\n\u001b[1;32m--> 353\u001b[0m chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat(messages, stop)\n\u001b[0;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_cache(query, chat_response\u001b[39m.\u001b[39mcontent)\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m chat_response\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\langchain\\chat_models\\base.py:128\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    126\u001b[0m     \u001b[39mself\u001b[39m, messages: List[BaseMessage], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    127\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(messages, stop\u001b[39m=\u001b[39;49mstop)\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\langchain\\chat_models\\promptlayer_openai.py:42\u001b[0m, in \u001b[0;36mPromptLayerChatOpenAI._generate\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpromptlayer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_api_key, promptlayer_api_request\n\u001b[0;32m     41\u001b[0m request_start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mtimestamp()\n\u001b[1;32m---> 42\u001b[0m generated_responses \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_generate(messages, stop)\n\u001b[0;32m     43\u001b[0m request_end_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mtimestamp()\n\u001b[0;32m     44\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\langchain\\chat_models\\openai.py:266\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop)\u001b[0m\n\u001b[0;32m    262\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[0;32m    263\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    265\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[1;32m--> 266\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(messages\u001b[39m=\u001b[39mmessage_dicts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\langchain\\chat_models\\openai.py:228\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\langchain\\chat_models\\openai.py:226\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[0;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[0;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    517\u001b[0m         method,\n\u001b[0;32m    518\u001b[0m         abs_url,\n\u001b[0;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    524\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\richt\\.conda\\envs\\Agent\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import deque\n",
    "from typing import Dict, Iterable, List, Set, Optional, Any\n",
    "\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from openai import InvalidRequestError\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import sqlite3\n",
    "\n",
    "class VirtualFile:\n",
    "    def __init__(self, content, page_size):\n",
    "        self.pages = [content[i:i+page_size] for i in range(0, len(content), page_size)]\n",
    "\n",
    "\n",
    "class VirtualFileSystem:\n",
    "    def __init__(self, page_size=2000):\n",
    "        self.virtual_files = {}\n",
    "        self.page_size = page_size\n",
    "\n",
    "    def dump_all(self, dump_directory=\"dump\"):\n",
    "        if not os.path.exists(dump_directory):\n",
    "            os.makedirs(dump_directory)\n",
    "\n",
    "        for file_name in self.virtual_files:\n",
    "            file_path = os.path.join(dump_directory, file_name)\n",
    "            with open(file_path, 'w') as f:\n",
    "                for page in self.virtual_files[file_name].pages:\n",
    "                    f.write(page)\n",
    "        return f\"All virtual files saved to '{dump_directory}' directory.\"\n",
    "\n",
    "\n",
    "    def create_file(self, file_name, content):\n",
    "        if file_name in self.virtual_files:\n",
    "            return f\"Error: File '{file_name}' already exists.\"\n",
    "        self.virtual_files[file_name] = VirtualFile(content, self.page_size)\n",
    "        return f\"File '{file_name}' created.\"\n",
    "\n",
    "    def read_file(self, file_name, page, include_surrounding=False, surrounding_chars=100):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        if page >= len(self.virtual_files[file_name].pages):\n",
    "            return f\"Error: Invalid page: {page}\"\n",
    "        \n",
    "        content = self.virtual_files[file_name].pages[page]\n",
    "\n",
    "        if include_surrounding:\n",
    "            prev_page = self.virtual_files[file_name].pages[page - 1] if page > 0 else \"\"\n",
    "            next_page = self.virtual_files[file_name].pages[page + 1] if page < len(self.virtual_files[file_name].pages) - 1 else \"\"\n",
    "\n",
    "            prev_content = prev_page[-surrounding_chars:] if prev_page else \"\"\n",
    "            next_content = next_page[:surrounding_chars] if next_page else \"\"\n",
    "\n",
    "            content = f\"{prev_content}{content}{next_content}\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    def update_file(self, file_name, page, new_content):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        if page >= len(self.virtual_files[file_name].pages):\n",
    "            return f\"Error: Invalid page: {page}\"\n",
    "        self.virtual_files[file_name].pages[page] = new_content\n",
    "        self.reorganize_pages(file_name)\n",
    "        return f\"File '{file_name}' updated at page {page}.\"\n",
    "\n",
    "    def save_to_disk(self, file_name, file_path=None):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        if not file_path:\n",
    "            file_path = file_name\n",
    "        with open(file_path, 'w') as f:\n",
    "            for page in self.virtual_files[file_name].pages:\n",
    "                f.write(page)\n",
    "        return f\"File '{file_name}' saved to disk at '{file_path}'.\"\n",
    "    \n",
    "    def load_from_disk(self, file_path, file_name=None):\n",
    "        if not os.path.exists(file_path):\n",
    "            return f\"Error: No such file on disk: '{file_path}'\"\n",
    "        if not file_name:\n",
    "            file_name = os.path.basename(file_path)\n",
    "        if file_name in self.virtual_files:\n",
    "            return f\"Error: File already exists in VFS: '{file_name}'\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        self.virtual_files[file_name] = VirtualFile(content, self.page_size)\n",
    "        return f\"File '{file_path}' loaded from disk into VFS as '{file_name}'.\"\n",
    "\n",
    "    def list_files(self):\n",
    "        output = \"Current available Files:\\n\"\n",
    "        for file_name in self.virtual_files.keys():\n",
    "            file = self.virtual_files[file_name]\n",
    "            output += f\"File '{file_name}' has {len(file.pages)} pages and a total size of {sum(len(page) for page in file.pages)} characters.\\n\"\n",
    "        return output+\"\\n\"\n",
    "\n",
    "    def delete_file(self, file_name):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        del self.virtual_files[file_name]\n",
    "        return f\"File '{file_name}' deleted.\"\n",
    "\n",
    "    def append_to_file(self, file_name, content):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        self.virtual_files[file_name].pages.extend(\n",
    "            [content[i:i+self.page_size] for i in range(0, len(content), self.page_size)]\n",
    "        )\n",
    "        return f\"Content appended to file '{file_name}'.\"\n",
    "\n",
    "    def rename_file(self, old_name, new_name):\n",
    "        if old_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{old_name}'\"\n",
    "        if new_name in self.virtual_files:\n",
    "            return f\"Error: File already exists: '{new_name}'\"\n",
    "        self.virtual_files[new_name] = self.virtual_files.pop(old_name)\n",
    "        return f\"File '{old_name}' renamed to '{new_name}'.\"\n",
    "\n",
    "    def get_file_info(self, file_name):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        file = self.virtual_files[file_name]\n",
    "        return f\"File '{file_name}' has {len(file.pages)} pages and a total size of {sum(len(page) for page in file.pages)} characters.\"\n",
    "\n",
    "    def reorganize_pages(self, file_name):\n",
    "        if file_name not in self.virtual_files:\n",
    "            return f\"Error: No such file: '{file_name}'\"\n",
    "        file = self.virtual_files[file_name]\n",
    "        content = \"\".join(file.pages)\n",
    "        file.pages = [content[i:i+self.page_size] for i in range(0, len(content), self.page_size)]\n",
    "        return f\"Pages reorganized for file '{file_name}'.\"\n",
    "    \n",
    "\n",
    "    def execute_command(self, command):\n",
    "        command_parts = command.split()\n",
    "        if not command_parts:\n",
    "            return \"Error: Empty command.\"\n",
    "\n",
    "        command_name = command_parts[0].upper()\n",
    "        args = command_parts[1:]\n",
    "\n",
    "        if command_name == \"CREATE_FILE\":\n",
    "            if len(args) == 1:\n",
    "                return self.create_file(args[0], \"\")\n",
    "            if len(args) < 2:\n",
    "                return \"Error: CREATE_FILE requires at least 2 arguments.\"\n",
    "            return self.create_file(args[0], \" \".join(args[1:]))\n",
    "\n",
    "        elif command_name == \"READ_FILE\":\n",
    "            if len(args) < 2:\n",
    "                return \"Error: READ_FILE requires at least 2 arguments.\"\n",
    "            include_surrounding = \"INCLUDE_SURROUNDING\" in args\n",
    "            if include_surrounding:\n",
    "                args.remove(\"INCLUDE_SURROUNDING\")\n",
    "            surrounding_chars_index = next((i for i, x in enumerate(args) if x == \"SURROUNDING_CHARS\"), None)\n",
    "            if surrounding_chars_index is not None and surrounding_chars_index + 1 < len(args):\n",
    "                surrounding_chars = int(args[surrounding_chars_index + 1])\n",
    "                args = args[:surrounding_chars_index] + args[surrounding_chars_index + 2:]\n",
    "            else:\n",
    "                surrounding_chars = 100\n",
    "            return self.read_file(args[0], int(args[1]), include_surrounding, surrounding_chars)\n",
    "\n",
    "        elif command_name == \"UPDATE_FILE\":\n",
    "            if len(args) < 3:\n",
    "                return \"Error: UPDATE_FILE requires at least 3 arguments.\"\n",
    "            return self.update_file(args[0], int(args[1]), \" \".join(args[2:]))\n",
    "\n",
    "        elif command_name == \"SAVE_TO_DISK\":\n",
    "            if len(args) < 1:\n",
    "                return \"Error: SAVE_TO_DISK requires at least 1 argument.\"\n",
    "            return self.save_to_disk(args[0], args[1] if len(args) > 1 else None)\n",
    "\n",
    "        elif command_name == \"LIST_FILES\":\n",
    "            return self.list_files()\n",
    "\n",
    "        elif command_name == \"DELETE_FILE\":\n",
    "            if len(args) < 1:\n",
    "                return \"Error: DELETE_FILE requires at least 1 argument.\"\n",
    "            return self.delete_file(args[0])\n",
    "\n",
    "        elif command_name == \"APPEND_TO_FILE\":\n",
    "            if len(args) < 2:\n",
    "                return \"Error: APPEND_TO_FILE requires at least 2 arguments.\"\n",
    "            return self.append_to_file(args[0], \" \".join(args[1:]))\n",
    "\n",
    "        elif command_name == \"RENAME_FILE\":\n",
    "            if len(args) < 2:\n",
    "                return \"Error: RENAME_FILE requires at least 2 arguments.\"\n",
    "            return self.rename_file(args[0], args[1])\n",
    "\n",
    "        elif command_name == \"GET_FILE_INFO\":\n",
    "            if len(args) < 1:\n",
    "                return \"Error: GET_FILE_INFO requires at least 1 argument.\"\n",
    "            return self.get_file_info(args[0])\n",
    "\n",
    "        elif command_name == \"REORGANIZE_PAGES\":\n",
    "            if len(args) < 1:\n",
    "                return \"Error: REORGANIZE_PAGES requires at least 1 argument.\"\n",
    "            return self.reorganize_pages(args[0])\n",
    "\n",
    "        elif command_name == \"DUMP_ALL\":\n",
    "            return self.dump_all(args[0] if args else None)\n",
    "\n",
    "        else:\n",
    "            return f\"Error: Unknown command '{command_name}'.\"\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, TaskDescription: str = \"dscr\", resultDescription:str = \"not solved\", Solved:bool = False):\n",
    "        self.Description:str = TaskDescription\n",
    "        self.ResultDescription:str = resultDescription\n",
    "        self.Solved:bool = Solved\n",
    "        self.ChildTasks:List[Task] = []\n",
    "        self.ParentTasks:List[Task] = []\n",
    "        \n",
    "    def __str__(self)->str:\n",
    "        if(self.Solved):\n",
    "            return \"Solved[\"+self.Description+\"]>>\"+self.ResultDescription\n",
    "        else:\n",
    "            return \"Unsolved[\"+self.Description+\"]>>\"+self.ResultDescription\n",
    "        \n",
    "    def get_recusively_all_subtasks(self, visited: Set['Task'] = None) -> List['Task']:\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if self in visited:\n",
    "            return []\n",
    "        all_tasks = []  # Add the current task to the list\n",
    "        for subtask in self.ChildTasks:\n",
    "            all_tasks.append(subtask)\n",
    "            all_tasks +=subtask.get_recusively_all_subtasks(visited)  # Recursively get all subtasks of the subtask\n",
    "        return all_tasks\n",
    "\n",
    "    def display(self, indent_level: int = 0) -> None:\n",
    "        indent = '  ' * indent_level  # Modify the number of spaces in the quotes to adjust indentation\n",
    "        if(self.Solved):\n",
    "            print(indent+\"Solved[\"+self.Description+\"]>>\"+self.ResultDescription.replace(\"\\n\",\"\"))\n",
    "        else:\n",
    "            print(indent+\"Unsolved[\"+self.Description+\"]>>\"+self.ResultDescription)\n",
    "        for subtask in self.ChildTasks:\n",
    "            subtask.display(indent_level + 1)\n",
    "    \n",
    "    def collect_parent_descriptions(self, visited: Set['Task'] = None) -> List[str]:\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if self in visited:\n",
    "            return []\n",
    "        visited.add(self)\n",
    "        descriptions = []\n",
    "        for parent_task in self.ParentTasks:\n",
    "            descriptions.append(parent_task.Description)\n",
    "            descriptions.extend(parent_task.collect_parent_descriptions(visited))\n",
    "        return descriptions\n",
    "    \n",
    "\n",
    "    def is_atomic(self)->bool:\n",
    "        return len(self.ChildTasks) == 0\n",
    "    \n",
    "    def ready_to_solve(self)->bool:\n",
    "            return all(map(lambda x: x.Solved, self.ChildTasks)) #all([]) is True\n",
    "        \n",
    "    def add_child(self, child: 'Task') -> None:\n",
    "        if child in self.ChildTasks:\n",
    "            return\n",
    "        self.ChildTasks.append(child)\n",
    "        child.ParentTasks.append(self)\n",
    "\n",
    "    def add_childs(self, childs: List['Task']) -> None:\n",
    "        for child in childs:\n",
    "            self.add_child(child)\n",
    "\n",
    "class Taskpool(List[Task]):    \n",
    "    def __str__(self)->str:\n",
    "        return \",\".join(map(str, self.tasks))\n",
    "    \n",
    "    def CreateContextSummery(self)->str:\n",
    "        return f\"/n\".join(map(lambda x: x.TaskDescription, self.tasks))\n",
    "    \n",
    "    def get_task_ready_to_solve(self)->Task:\n",
    "        for task in self:\n",
    "            if(task.Solved):\n",
    "                continue\n",
    "            if(task.ready_to_solve()):\n",
    "                return task\n",
    "        raise Exception(\"No task ready to solve\")\n",
    "    \n",
    "    def get_nummerated_task_List(self) -> str:\n",
    "        formatted_tasks = []\n",
    "        for index, task in enumerate(self):\n",
    "            formatted_tasks.append(f\"{index}:{task.Description}\")\n",
    "        return \"\\n\".join(formatted_tasks)\n",
    "    \n",
    "class CachedChat:\n",
    "    def __init__(self):\n",
    "        self.conn = None\n",
    "        self.chat = PromptLayerChatOpenAI(model_name=\"gpt-4\",temperature=0.2, request_timeout=380)\n",
    "        # self.chat = PromptLayerChatOpenAI(temperature=0.2, request_timeout=180)\n",
    "\n",
    "    def __call__(self, messages, stop=None):\n",
    "\n",
    "        return AIMessage(\n",
    "            content=self.run_chat(messages, stop)\n",
    "        )\n",
    "    \n",
    "    def establish_connection(self):\n",
    "        self.conn = sqlite3.connect('cache.db')\n",
    "\n",
    "    def check_cache(self, query):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"SELECT response FROM cache WHERE query=?\", (query,))\n",
    "        result = cursor.fetchone()\n",
    "        return result[0] if result else None\n",
    "\n",
    "    def store_cache(self, query, response):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"INSERT INTO cache(query, response) VALUES (?, ?)\", (query, response))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def create_cache_table(self):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS cache\n",
    "                        (query TEXT PRIMARY KEY, response TEXT)''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def run_chat(self, messages, stop) -> str:\n",
    "        query = str((messages, stop))\n",
    "        self.establish_connection()\n",
    "        self.create_cache_table()\n",
    "        cached_response = self.check_cache(query)\n",
    "\n",
    "        if cached_response:\n",
    "            return cached_response\n",
    "\n",
    "        chat_response = self.chat(messages, stop)\n",
    "        self.store_cache(query, chat_response.content)\n",
    "\n",
    "        return chat_response.content\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, Objectiv: str):\n",
    "        self.Objectiv:Task = Task(Objectiv)\n",
    "        self.Taskpool = Taskpool()\n",
    "        self.Taskpool.append(self.Objectiv)\n",
    "        # self.chat = ChatOpenAI(temperature=0)\n",
    "        #self.chat = PromptLayerChatOpenAI(temperature=0.2)\n",
    "        self.chat=CachedChat()\n",
    "\n",
    "        self.VirtualFileSystem=VirtualFileSystem(page_size=2000)\n",
    "        self.SelfDescription = \"\"\"Alright, so you're part of an autonomous agent that utilizes a sophisticated tool called ChatGPT to divide complex tasks into smaller, more manageable ones, and than solves them. Although ChatGPT is quite intelligent, its context awareness is limited, so we have to employ a paging system to assist it in retaining and processing data. Our communication among team members is facilitated through file sharing. We extract information from files and store the results in files as well. To ensure the timely and efficient execution of the current task, our task splitter coordinates the data flow, guaranteeing that we have all the necessary preparations at our disposal.\"\"\"\n",
    "        self.command_documentation = \"\"\"Command Documentation\n",
    "CALL CREATE_FILE <file_name>\n",
    "<content>\n",
    "ENDCALL\n",
    "- Creates a new file with the given name and content.\n",
    "\n",
    "CALL READ_FILE <file_name> <page> [INCLUDE_SURROUNDING] [SURROUNDING_CHARS <num_chars>]\n",
    "ENDCALL\n",
    "- Reads the specified page of the file. Optionally, include surrounding content from adjacent pages with the specified number of characters.\n",
    "\n",
    "CALL UPDATE_FILE <file_name> <page>\n",
    "<new_content>\n",
    "ENDCALL\n",
    "- Updates the specified page of the file with the new content.\n",
    "\n",
    "CALL LIST_FILES\n",
    "ENDCALL\n",
    "- Lists all the files in the FS.\n",
    "\n",
    "CALL DELETE_FILE <file_name>\n",
    "ENDCALL\n",
    "- Deletes the specified file from the FS.\n",
    "\n",
    "CALL APPEND_TO_FILE <file_name>\n",
    "<content>\n",
    "ENDCALL\n",
    "- Appends the given content to the specified file.\n",
    "\n",
    "CALL RENAME_FILE <old_name> <new_name>\n",
    "ENDCALL\n",
    "- Renames the specified file to the new name.\n",
    "\n",
    "CALL GET_FILE_INFO <file_name>\n",
    "ENDCALL\n",
    "- Retrieves information about the specified file, such as the number of pages and total size.\n",
    "\n",
    "CALL FINISH\n",
    "<Summary of files created and their contents as hints for Parent Tasks>\n",
    "ENDCALL\n",
    "- Returns the summary of files created and their contents as hints for Parent Tasks. This ends the solving of the task. Call this when you are done.\n",
    "\n",
    "Example:\n",
    "CALL CREATE_FILE test.txt\n",
    "This is the content of the file\n",
    "ENDCALL\n",
    "\n",
    "The first Page in a File is Page number 0.\n",
    "\n",
    "Only ever create one command. You will be provided the results of an command and than are prompted again to create a new Command.\n",
    "Its not your task to simulate the command execution! Dont create Returnmessages for Commands.\n",
    "\n",
    "Suggested Workflow:\n",
    "Get current list of files.\n",
    "Read Files that could be usefull, if any\n",
    "Create new File with your solution\n",
    "finish with FINISH command\n",
    "\n",
    "\"\"\"\n",
    "    def extract_json(self,text):\n",
    "        # Find a JSON object or array pattern in the text\n",
    "        pattern = r'({.*?}|\\[.*?\\])'\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "        # Check if a match is found\n",
    "        if match:\n",
    "            json_str = match.group()\n",
    "            try:\n",
    "                # Parse the JSON string into a Python object\n",
    "                json_obj = json.loads(json_str)\n",
    "                return json_obj\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Invalid JSON detected.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"No JSON found in the text.\")\n",
    "            return None\n",
    "\n",
    "    def should_be_split(self, task: Task) -> bool:\n",
    "        #test if task is atomic if no throw exception\n",
    "        if len(task.ChildTasks) != 0:\n",
    "            raise ValueError(\"Task is not atomic\")\n",
    "        \n",
    "        print(\"Now in should_be_slpit:\" + task.Description)\n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "        messages = []\n",
    "        messages.append(SystemMessage(content=\n",
    "                                      \"You are an AI that determines if a task could be split into multiple simpler tasks. Return 'True' if it could be split and 'False' otherwise. Dont be chaty.\"))\n",
    "        \n",
    "        messages.append(HumanMessage(content=\n",
    "                                     f\"Return 'True' if it could be split and 'False' otherwise. Task description: {task.Description}\"))\n",
    "        \n",
    "        max_retries = 3\n",
    "        for _ in range(max_retries):\n",
    "            response = self.chat(messages).content\n",
    "            clean_response = response.strip().lower()\n",
    "\n",
    "            if 'true' in clean_response:\n",
    "                return True\n",
    "            elif 'false' in clean_response:\n",
    "                return False\n",
    "            else:\n",
    "                messages.append(HumanMessage(content=\"Please provide a valid response with either 'True' or 'False'.\"))\n",
    "        raise ValueError(\"AI response does not contain a valid boolean string after multiple retries: \" + response)\n",
    "\n",
    "    def SplitTask(self, task: Task, verbose: bool = True) -> List[Task]:\n",
    "        print(\"Now in SplitTask:\" + task.Description)\n",
    "\n",
    "        messages = []\n",
    "\n",
    "        messages.append(SystemMessage(content=f\"\"\"{self.SelfDescription}\n",
    "\n",
    "As a Task Splitting AI, your objective is to analyze the main task provided and create smaller, independent, and manageable subtasks that contribute to its successful completion. Create a hierarchical view, prioritizing tasks that need to be completed first. Ensure that the subtasks do not expand the scope of the main task and follow it literally. Keep in mind the limited context problem faced by language models like ChatGPT when processing and generating text that exceeds their maximum token limit.\n",
    "\n",
    "In each subtask:\n",
    "- Instruct the use of the FileSystem to store results.\n",
    "- Return information about the created or modified files, along with a brief description of their contents.\n",
    "\n",
    "Clearly define the expected results and file names for each task to be produced. You cannot create variables, only files. Always instruct each task to call the FINISH command at the end.\n",
    "\n",
    "The TaskSolver has the following commands available:\n",
    "CREATE_FILE, READ_FILE, UPDATE_FILE, LIST_FILES, DELETE_FILE, APPEND_TO_FILE, RENAME_FILE, GET_FILE_INFO, and FINISH.\n",
    "\n",
    "Do not number your tasks, but list them in the order they should be executed.\n",
    "\n",
    "Well working example of an subtask has been:\n",
    "The File FinalAGI.py is loaded for you. Simply call the ReadFile Command to read each Page of that file. After you have read a page, apend a summary to the file summary.txt. After you have read all pages, call the FINISH command and write a short summary of your findings.\n",
    "\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "        # Check if the task has any parent tasks\n",
    "        # parent_descriptions = task.collect_parent_descriptions()\n",
    "        # if parent_descriptions:\n",
    "        #     # Include the descriptions of the parent tasks in the task description\n",
    "        #     task_description = f\" Maintask: {task.Description}. The context of the parent tasks is: {', '.join(parent_descriptions)}\"\n",
    "        #     task_description += \"\\n Use this context to split the main task into smaller, independent, and more manageable subtasks.\"\n",
    "        #     messages.append(HumanMessage(content=task_description))\n",
    "        # else:\n",
    "        #     messages.append(HumanMessage(content=MainPromp+ \"\"\" Main task to split: \"\"\" + task.Description))\n",
    "\n",
    "        # Call OpenAI\n",
    "\n",
    "        messages.append(HumanMessage(content=\"\"\"Main task to split: \"\"\" + task.Description))\n",
    "        generation = self.chat(messages)\n",
    "\n",
    "        print(\"Splitted Tasks before JSON packing: \" + generation.content)\n",
    "\n",
    "\n",
    "        #refinment step\n",
    "        messages.append(generation)\n",
    "        messages.append(HumanMessage(content=\"\"\"Have you followed ale the rules descriped to create this task list? How could better Subtasks look?\"\"\"))\n",
    "        generation = self.chat(messages)\n",
    "        messages.append(generation)\n",
    "\n",
    "        #human feedback step\n",
    "        print(generation.content)\n",
    "        print(\"What do you want to change at this plan? Simply press Enter if happy\")\n",
    "        while True:\n",
    "            feedback = input()\n",
    "            if feedback.strip() == \"\":\n",
    "                break\n",
    "            else:\n",
    "                messages.append(HumanMessage(content = f\"The Operator wants this changes to the plan: {feedback}\"))\n",
    "                generation = self.chat(messages)\n",
    "                messages.append(generation)\n",
    "                print(generation.content)\n",
    "                print(\"What do you want to change at this plan? Simply press Enter if happy\")\n",
    "\n",
    "        # JSON Packaging step\n",
    "        messages.append(generation)\n",
    "        messages.append(HumanMessage(content=\"\"\"Now put this Tasks with their complete description in full detail in an element of a JSON Array like [\"Complete Description of first Task....\", \"Complete description of second Task....\"].\"\"\"))\n",
    "\n",
    "        # Call OpenAI\n",
    "        JSONSTR = self.chat(messages).content\n",
    "        print(\"Splitted Tasks as JSON \" + JSONSTR)\n",
    "\n",
    "        JSON = self.extract_json(JSONSTR)\n",
    "\n",
    "        Tasks = []\n",
    "\n",
    "        for subtaskstr in JSON:\n",
    "            Tasks.append(Task(TaskDescription=str(subtaskstr)))\n",
    "\n",
    "        # Link the tasks as child tasks in a sequential manner, each task is a child task of the task before it\n",
    "        Tasks.reverse()  # Last Task depends on Tasks before it so he is the first with a child\n",
    "        task.add_child(Tasks[0])\n",
    "        for i in range(len(Tasks) - 1):\n",
    "            Tasks[i].add_child(Tasks[i + 1])\n",
    "\n",
    "        return Tasks\n",
    "    \n",
    "    def SolveAtomicTask(self, task: Task, max_retries: int = 5, verbose: bool = True) -> Task:\n",
    "        ContextHeader = []\n",
    "        ContextHeader.append(SystemMessage(content=f\"\"\"{self.SelfDescription}\n",
    "You are an AI designed to solve tasks by understanding the requirements, performing necessary file operations, and delivering the results. Stay focused on the task and adhere to the command documentation. Save the task results in files and provide a brief message indicating the created files and a concise description of their contents. Once completed, use the FINISH command.\"\"\"))\n",
    "\n",
    "        # # Include Parent Tasks in the task description\n",
    "        # parent_descriptions = task.collect_parent_descriptions()\n",
    "        # parent_descriptions.reverse() # Reverse the order of the parent descriptions so that the 'nearest' parent is last to be included in the task description (most relevant to the current task)\n",
    "        # if parent_descriptions:\n",
    "        #     task_description = f\"Current Task: {task.Description}. \\n\\n This Current Task will be used to solve the parent tasks. Keep that in mind while solving it, so its solved in a way, its usefull in the parent Tasks.\\n\\n Parent Tasks: {os.linesep.join(parent_descriptions)}\"\n",
    "\n",
    "        #     finalMessages.append(HumanMessage(content=task_description))\n",
    "\n",
    "        # childs = task.get_recusively_all_subtasks()\n",
    "        # if len(childs) > 0:\n",
    "        #     task_description = f\"Current Task: {task.Description}. The Current Task has Subtasks that are solved. The results and descriptions of the child tasks are:\\n\\n\" + '\\n\\n'.join(map(lambda t: (t.Description + \": \" + t.ResultDescription), childs))\n",
    "        #     task_description += \"\\n Use these results to solve the current task.\"\n",
    "        #     finalMessages.append(HumanMessage(content=task_description))\n",
    "\n",
    "        ContextHeader.append(HumanMessage(content=self.command_documentation))\n",
    "\n",
    "        ContextHeader.append(HumanMessage(content=self.VirtualFileSystem.list_files()))\n",
    "        ContextHeader.append(HumanMessage(content=f\"Current Task: {task.Description}\"))\n",
    "\n",
    "        workingLog = []\n",
    "        for i in range(200): #max 10 commands\n",
    "            workingLog.append(HumanMessage(content=\"We now make a thinking step, no commands can be send. Think step by step. What Command would be right next one? How is it used? You can only call one command at a time. No Piping is possible. This is just the planingphase!\"))\n",
    "\n",
    "            # call OpenAI for Chain of Thought\n",
    "            toLong = True\n",
    "            while toLong:\n",
    "                try:\n",
    "                    workingLog.append(self.chat(ContextHeader + workingLog))\n",
    "                    toLong = False\n",
    "                except InvalidRequestError:\n",
    "                    workingLog=workingLog[1:] # remove one from working log and try again\n",
    "                    print(\"Removed one message from working log and try again\")\n",
    "            \n",
    "\n",
    "            # Call OpenAI for Command\n",
    "            workingLog.append(HumanMessage(content=\"Now CALL the Command you thought of with the actual Contend. Remember you can only Call one command at a time. No Piping is possible.\"))\n",
    "            \n",
    "            toLong = True\n",
    "            while toLong:\n",
    "                try:\n",
    "                    solutionMessage = self.chat(ContextHeader + workingLog, stop=[\"ENDCALL\"])\n",
    "                    toLong = False\n",
    "                except InvalidRequestError:\n",
    "                    workingLog=workingLog[1:] # remove one from working log and try again\n",
    "                    print(\"Removed one message from working log and try again\")\n",
    "\n",
    "            \n",
    "            solutionMessage.content+=\"\\nENDCALL\" #get the stop back in\n",
    "            \n",
    "            workingLog.append(solutionMessage)\n",
    "\n",
    "\n",
    "            generation = solutionMessage.content.strip()\n",
    "            #todo extract command from generation\n",
    "            command_start = generation.find(\"CALL\")\n",
    "            command_end = generation.find(\"ENDCALL\")\n",
    "            if command_start != -1 and command_end != -1:\n",
    "                command = generation[command_start + 4:command_end].strip()\n",
    "                \n",
    "                if \"CALL FINISH\" in generation:\n",
    "                    task.ResultDescription = command.replace(\"FINISH\\n\", \"\").strip()\n",
    "                    task.Solved = True\n",
    "                    return task\n",
    "\n",
    "                command_result = self.VirtualFileSystem.execute_command(command)\n",
    "\n",
    "                if command_result:\n",
    "                    workingLog.append(HumanMessage(content=\"Command Return:\\n\"+command_result))\n",
    "\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Retry {i + 1}: Command not found in generation.\")\n",
    "        return task\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        #hardcoded passes of possible splitting\n",
    "        for i in range(0):\n",
    "            currentTasks = Taskpool()\n",
    "            currentTasks.extend(self.Taskpool) #create copy of Taskpool or else loop will be endless\n",
    "            for task in currentTasks:\n",
    "                if task.is_atomic():\n",
    "                    #if self.should_be_split(task):\n",
    "                    splitDone=True\n",
    "                    print(\"Splitting Task\")\n",
    "                    newTasks = self.SplitTask(task)\n",
    "                    self.Taskpool.extend(newTasks)\n",
    "                    self.Objectiv.display()\n",
    "                    print(\"Splitting Done\")\n",
    "        \n",
    "        print(self.Taskpool.get_nummerated_task_List())\n",
    "\n",
    "        while self.Objectiv.Solved==False:\n",
    "            currentTask=self.Taskpool.get_task_ready_to_solve()\n",
    "            #self.DummySolveAtomicTask(currentTask)\n",
    "            self.SolveAtomicTask(currentTask)\n",
    "            self.Objectiv.display()\n",
    "\n",
    "# agent = Agent(\"Create a file containing a workflow how to write a novel\")\n",
    "# agent = Agent(\"Write a single HTML file in wich with JavaScript two AIs play Connect 4 against each other. The User only watches, and restarts.\")\n",
    "\n",
    "# agent=Agent(\"The File FinalAGI.py is loaded for you. Simply call the ReadFile Command to read each Page of that file. After you have read a page, apend a summary to the file summary.txt. After you have read all pages, call the FINISH command and write a short summary of your findings.\")\n",
    "# agent=Agent(\"Look at Page 5 of the file FinalAGI.py. Can you find a way to improve the code on that page? If so, replace the code on that page with your improved code. After you have replaced the code, create a file called changes.txt and write a short summary of your changes.\")\n",
    "\n",
    "agent.VirtualFileSystem.load_from_disk(\"FinalAGI.py\")\n",
    "agent.run()\n",
    "agent.VirtualFileSystem.dump_all()\n",
    "\n",
    "print(agent.Objectiv.ResultDescription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
